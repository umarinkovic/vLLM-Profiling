#!/usr/bin/env python3

"""

orhcestrator.py - script for running models on the available GPUs automatically

This script orchestrates and executes the configured models on the configured GPUs.

"""

import argparse
from collections import defaultdict, deque
import subprocess
from pathlib import Path
import yaml
import os

PROJECT_ROOT = Path(__file__).parent.parent.parent


def prepare_tokens():
    tokens_path = PROJECT_ROOT / ".config" / "tokens.yaml"
    if not tokens_path.exists():
        print(f"No {tokens_path} file found.")
        return
    with tokens_path.open("r") as f:
        tokens = yaml.safe_load(f)["tokens"]
    for key, value in tokens.items():
        os.environ[key] = value


def parse_gpus():
    file_path = PROJECT_ROOT / ".config" / "gpus.yaml"
    if not file_path.exists():
        subprocess.run(["generate_gpu_yaml.sh"], check=True)
    with file_path.open("r") as f:
        return [
            gpu for gpu in yaml.safe_load(f)["gpus"] if not gpu.get("disabled", False)
        ]


def parse_models(models_filter=None):
    file_path = PROJECT_ROOT / "yaml" / "models.yaml"
    if not file_path.exists():
        raise FileNotFoundError(f"No {file_path} found.")
    with open(file_path, "r") as f:
        return [
            model
            for model in yaml.safe_load(f)[f"models"]
            if not models_filter or model["name"] in models_filter
            # TODO: add regex to the models_filter
        ]


def run(docker_image, num_procs, script, duration, iterations, models_filter):
    gpus = parse_gpus()
    models = parse_models(models_filter)

    # create a map {device_name -> queue({model_to_run, environment})}
    device_task_queue_map = defaultdict(deque)
    for gpu in gpus:
        for model in models:
            if gpu["name"] not in model.get("disabled_on", []):
                # environment is generated by taking the env dictionary from the model and superimposing the env dictionary of the gpu
                device_task_queue_map[gpu["device"]].append(
                    {"model": model, "env": model.get("env", {}) | gpu.get("env", {})}
                )

    device_to_name_map = {gpu["device"]: gpu["name"] for gpu in gpus}
    prepare_tokens()

    # TODO: implement parallelism, currently writing single threaded but will be expanded later
    # to include the possibility of starting multiple profiling tasks on different GPUs
    devices = list(device_task_queue_map.keys())
    while any(device_task_queue_map.values()):
        for device in devices:
            task_queue = device_task_queue_map[device]
            if task_queue:
                task = task_queue.popleft()
                model = task["model"]
                env = task["env"]
                iter_dur_arg = (
                    ["--duration", str(duration)]
                    if duration
                    else ["--iterations", str(iterations)]
                )
                script_args = [
                    "--script",
                    model["script"],
                    "--model",
                    model["name"],
                    "--prompts-path",
                    f"/workspace/yaml/prompts/{model['type']}.yaml",
                    "--resources-path",
                    f"/workspace/images/{model['type']}",
                    *iter_dur_arg,
                ]
                subprocess.call(
                    [
                        "scripts/host/docker_tool.py",
                        "run",
                        "--image-name",
                        docker_image,
                        "--device-name",
                        device_to_name_map[device],
                        "--device",
                        device,
                        "--script",
                        script,
                        "--",
                    ]
                    + script_args,
                    env=os.environ | env,
                )


def main():
    parser = argparse.ArgumentParser(
        "Orchestrate profiling of given models on available AMD GPUs"
    )
    parser.add_argument(
        "--docker-image",
        help="Docker image on which to run vllm",
        default="hyoon11/vllm-dev:20260121_43_py3.12_torch2.9_triton3.5_navi_upstream_6a09612_ubuntu24.04",
    )
    parser.add_argument(
        "--num-procs",
        help="""One GPU always runs one profiling task at a time.
                        On a system with multiple GPUs, we can choose to run multiple
                        profiling tasks (1 for each GPU maximum), if resource exhaustion
                        is not a problem (RAM being the main concern)""",
        default=1,
    )
    parser.add_argument(
        "--script",
        help="Name of the script to run inside the containers.",
        default="run_model.py",
    )
    time_group = parser.add_mutually_exclusive_group(required=True)
    time_group.add_argument
    time_group.add_argument(
        "--duration",
        help="Duration of time (seconds) the model should be running",
        type=int,
    )
    time_group.add_argument(
        "--iterations", help="Number of iterations the model should run for", type=int
    )
    parser.add_argument(
        "models_filter",
        help="Subset of models to run from the models.yaml file. If left empty, runs all models.",
        nargs="*",
    )

    args = parser.parse_args()
    # TODO: remove default docker image from this file (put it in some config)

    run(
        docker_image=args.docker_image,
        num_procs=args.num_procs,
        script=args.script,
        duration=args.duration,
        iterations=args.iterations,
        models_filter=args.models_filter,
    )


if __name__ == "__main__":
    main()
